{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lib.preprocessing import *\n",
    "from lib.cleaning import *\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDRegressor   \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "# from mpl_toolkits.basemap import Basemap\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# import missingno as msno"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_sample(percentage=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.Series(df.columns.format())\n",
    "\n",
    "metrics = [\"Temperature\", \"Precipitation in millimeters\", \"Distance (KM)\"]  # 3 of these\n",
    "\n",
    "ids = pd.concat([cols.loc[cols.str.match(\".*Id.*\")], cols.loc[cols.str.match(\".*No.*\")]]) # 3 of these\n",
    "\n",
    "location = [\"Pickup Lat\", \"Pickup Long\", \"Destination Lat\", \"Destination Long\"] # 4 of these\n",
    "times = cols.loc[cols.str.match(\".*Time.*\")] # 6(actually 4) of these\n",
    "\n",
    "types = [\"Vehicle Type\", \"Platform Type\", \"Personal or Business\", ] # 3 of these\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = pd.read_csv(\"variable_definitions.csv\")\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df.Temperature, bins=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['Placement - Day of Month'] < df[\"Pickup - Day of Month\"])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nelson cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_sample(percentage=1, csv_file=\"data/train_full.csv\")\n",
    "df = drops(df)\n",
    "df = impute_temperature(df)\n",
    "df = combine_weekdays(df)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df.Temperature, bins=35)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emily Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_sample(percentage = 1, sql_db='data/cleaned_nelson.db')\n",
    "\n",
    "for i in ['Order No', 'User Id', \"Rider Id\"]:\n",
    "    under = i.replace(' ', '_')\n",
    "    data.rename(columns={i: under}, inplace=True)\n",
    "    data[under] = data[under].str.replace(f'{under}_', '')\n",
    "    data[under] = data[under].astype(int)\n",
    "\n",
    "save_data(data, sql_db='data/cleaned_emily.db')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging Emily w/ Nelson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = load_sample(percentage=1, sql_db=\"data/cleaned_emily.db\")\n",
    "em.rename({\n",
    "    \"Order_No\" : \"order_no\",\n",
    "    \"User_Id\" : \"user_id\",\n",
    "    \"Rider_Id\" : \"rider_id\"\n",
    "}, axis=1, inplace=True)\n",
    "em.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(em, sql_db=\"data/cleaned_emily_nelson.db\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alex Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riders = pd.read_csv(\"data/riders.csv\")\n",
    "\n",
    "# rename cols-- easier to work with\n",
    "riders.rename(columns= {\n",
    "    \"Rider Id\": \"id\",\n",
    "    \"No_Of_Orders\": \"orders\",\n",
    "    \"Age\": \"age\",\n",
    "    \"Average_Rating\": \"average_rating\",\n",
    "    \"No_of_Ratings\": \"number_rating\" \n",
    "}, inplace=True)\n",
    "\n",
    "# drop \"Rider_Id_\" in \"id\" column\n",
    "riders.id.replace('Rider_Id_', ' ',regex=True,inplace=True)\n",
    "\n",
    "riders.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(riders, sql_db=\"data/cleaned_Alex.db\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging Alex w/ Emily+Nelson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riders_clean = load_sample(percentage=1, sql_db=\"data/cleaned_Alex.db\")\n",
    "riders_clean[\"id\"] = riders_clean[\"id\"].astype(int)\n",
    "riders_clean.set_index(\"id\", inplace=True)\n",
    "riders_clean.head(3)\n",
    "# riders_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_clean = load_sample(percentage=1, sql_db=\"data/cleaned_emily_nelson.db\")\n",
    "other_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_all = other_clean.join(riders_clean, on=\"rider_id\", rsuffix=\"_rider\")\n",
    "cleaned_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(cleaned_all, sql_db=\"data/cleaned_alex_emily_nelson.db\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_sample(percentage=0.5, sql_db=\"data/cleaned_alex_emily_nelson.db\")\n",
    "\n",
    "df[\"Placement - Time\"] = get_seconds_from_dt_series(df['Placement - Time'])\n",
    "df[\"Confirmation - Time\"] = get_seconds_from_dt_series(df['Confirmation - Time'])\n",
    "df[\"Arrival at Pickup - Time\"] = get_seconds_from_dt_series(df['Arrival at Pickup - Time'])\n",
    "df[\"Pickup - Time\"] = get_seconds_from_dt_series(df['Pickup - Time'])\n",
    "df[\"Business\"] = (df['Personal or Business'] == \"Business\").astype(float)\n",
    "df[\"place_to_confirm\"] = df[\"Confirmation - Time\"] - df[\"Placement - Time\"]\n",
    "df[\"confirm_to_pick_arr\"] = df[\"Arrival at Pickup - Time\"] - df[\"Confirmation - Time\"]\n",
    "df[\"pick_arr_to_pick\"] = df['Pickup - Time'] - df[\"Arrival at Pickup - Time\"]\n",
    "df['platform_4'] = (df['Platform Type'] == 4).astype(float)\n",
    "df.drop(columns=[\"Personal or Business\", \"Vehicle Type\", \"Platform Type\"], inplace=True)\n",
    "\n",
    "dont_scale = [\"order_no\", \"user_id\", \"rider_id\", \"Business\", \"platform_4\", 'Time from Pickup to Arrival']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(df[df.columns[~df.columns.isin(dont_scale)]])\n",
    "X = pd.DataFrame(X, columns = df.columns[~df.columns.isin(dont_scale)])\n",
    "df = pd.concat([X, df[df.columns[df.columns.isin(dont_scale)]]], axis=1)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train[[\n",
    "    # \"Placement - Day of Month\", \n",
    "    # \"Placement - Weekday (Mo = 1)\", \n",
    "    # \"Placement - Time\", \n",
    "    # \"Confirmation - Time\",\n",
    "    # \"Arrival at Pickup - Time\",\n",
    "    # \"Pickup - Time\",\n",
    "    \"place_to_confirm\",\n",
    "    \"confirm_to_pick_arr\",\n",
    "    \"pick_arr_to_pick\",\n",
    "    \"Distance (KM)\",\n",
    "    \"Temperature\",\n",
    "    # \"Pickup Lat\",\n",
    "    # \"Pickup Long\",\n",
    "    # \"Destination Lat\",\n",
    "    # \"Destination Long\",\n",
    "    # \"Fulfillment - Weekday (Su = 0)\",\n",
    "    # \"Fulfillment - Day of Month\",\n",
    "    \"orders\",\n",
    "    \"age\",\n",
    "    \"average_rating\",\n",
    "    \"number_rating\",\n",
    "    \"Business\"\n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_model(model) -> pd.DataFrame:\n",
    "    return pd.DataFrame(cross_validate(\n",
    "        model, \n",
    "        train[train.columns[train.columns!='Time from Pickup to Arrival']],\n",
    "        train[['Time from Pickup to Arrival']],\n",
    "        scoring={\"neg_mse\": \"neg_mean_squared_error\", \"neg_mae\": \"neg_mean_absolute_error\"}\n",
    "    ))\n",
    "\n",
    "models = [\n",
    "    (DecisionTreeRegressor(), \"DTree\"),\n",
    "    (LinearRegression(), \"OLS\"),\n",
    "    (Lasso(), \"Lasso\"),\n",
    "    (Ridge(), \"Ridge\"),\n",
    "    (KNeighborsRegressor(n_neighbors=20), \"20-KNN\"),\n",
    "    (SGDRegressor(), \"SGD\"),\n",
    "    (GaussianProcessRegressor(), \"Gaussian\"),\n",
    "    (MLPRegressor(), \"Dense NN\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for model, name in models:\n",
    "    print(name, ':')\n",
    "    print(assess_model(model))\n",
    "    print()\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
